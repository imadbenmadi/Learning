{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this class cover?\n",
    "\n",
    "The Scikit-Learn library is very capable. However, learning everything off by heart isn't necessary. \n",
    "Instead, this notebook focuses some of the main use cases of the library.\n",
    "\n",
    "\n",
    "## Where can I get help?\n",
    "\n",
    "This notebook goes through a range of common and useful featues of the Scikit-Learn library.\n",
    "\n",
    "It's long but it's called quick because of how vast the Scikit-Learn library is. Covering everything requires a [full-blown documentation](https://scikit-learn.org/stable/user_guide.html), of which, if you ever get stuck, you should read.\n",
    "\n",
    "\n",
    "If you get stuck or think of something you'd like to do which this notebook doesn't cover, don't fear!\n",
    "\n",
    "The recommended steps you take are:\n",
    "1. **Try it** - Since Scikit-Learn has been designed with usability in mind, your first step should be to use what you know and try figure out the answer to your own question (getting it wrong is part of the process). If in doubt, run your code.\n",
    "2. **Press SHIFT+TAB** - See you can the docstring of a function (information on what the function does) by pressing **SHIFT + TAB** inside it. Doing this is a good habit to develop. It'll improve your research skills and give you a better understanding of the library. \n",
    "3. **Search for it** - If trying it on your own doesn't work, since someone else has probably tried to do something similar, try searching for your problem. You'll likely end up in 1 of 2 places:\n",
    "    * [Scikit-Learn documentation/user guide](https://scikit-learn.org/stable/user_guide.html) - the most extensive resource you'll find for Scikit-Learn information.\n",
    "    * [Stack Overflow](https://stackoverflow.com/) - this is the developers Q&A hub, it's full of questions and answers of different problems across a wide range of software development topics and chances are, there's one related to your problem.\n",
    "    \n",
    "An example of searching for a Scikit-Learn solution might be:\n",
    "\n",
    "> \"how to tune the hyperparameters of a sklearn model\"\n",
    "\n",
    "Searching this on Google leads to the Scikit-Learn documentation for the `GridSearchCV` function: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "\n",
    "The next steps here are to read through the documentation, check the examples and see if they line up to the problem you're trying to solve. If they do, **rewrite the code** to suit your needs, run it, and see what the outcomes are.\n",
    "\n",
    "4. **Ask for help** - If you've been through the above 3 steps and you're still stuck, you might want to ask your question on [Stack Overflow](https://www.stackoverflow.com). Be as specific as possible and provide details on what you've tried.\n",
    "\n",
    "Remember, you don't have to learn all of the functions off by heart to begin with. \n",
    "\n",
    "What's most important is continually asking yourself, **\"what am I trying to do with the data?\"**.\n",
    "\n",
    "Start by answering that question and then practicing finding the code which does it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Regression Problem with Scikit-Learn\n",
    "\n",
    "#### **California Housing Dataset**\n",
    "- A real-world dataset provided by Scikit-Learn.\n",
    "- **Goal**: Predict the median house value (in hundreds of thousands of dollars) for California districts.\n",
    "- **Features**:\n",
    "  - Age of the home\n",
    "  - Number of rooms\n",
    "  - Number of bedrooms\n",
    "  - Population living in the area\n",
    "  - Average income\n",
    "  - Other district-level features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Load the Dataset**\n",
    "   - Use `fetch_california_housing` from `sklearn.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  target  \n",
       "0        -122.23   4.526  \n",
       "1        -122.22   3.585  \n",
       "2        -122.24   3.521  \n",
       "3        -122.25   3.413  \n",
       "4        -122.25   3.422  \n",
       "...          ...     ...  \n",
       "20635    -121.09   0.781  \n",
       "20636    -121.21   0.771  \n",
       "20637    -121.22   0.923  \n",
       "20638    -121.32   0.847  \n",
       "20639    -121.24   0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df[\"target\"] = pd.Series(housing[\"target\"])\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, our goal here is to use the feature columns, such as:\n",
    "* `MedInc` - median income in block group\n",
    "* `HouseAge` - median house age in block group\n",
    "* `AveRooms` - average number of rooms per household\n",
    "* `AveBedrms` - average number of bedrooms per household\n",
    "\n",
    "To predict the `target` column which expresses the median house value for specfici California districts in hundreds of thousands of dollars ($100,000). \n",
    "\n",
    "In essence, each row is a different district in California (the data) and we're trying to build a model to predict the median house value in that distract (the target/label) given a series of attributes about the houses in that district.\n",
    "\n",
    "Since we have data and labels, this is a supervised learning problem. And since we're trying to predict a number, it's a regression problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric\n",
    "- Mean squared Error\n",
    "- R² score\n",
    "\n",
    "Imagine you're trying to predict house prices based on their size using a linear equation.\n",
    "\n",
    "R² helps you understand how well the model explains the relationship between size and house price.\n",
    "\n",
    "R² is like a score that tells you how good the model is at predicting price from size.\n",
    "It ranges from 0 to 1:\n",
    "\n",
    "- 0 means your the model doesn't help at all in predicting price from size.\n",
    "- 1 means your the model perfectly predicts price from size.\n",
    "\n",
    "So, if you have an R² of 0.8, it means 80% of the variation in price can be explained by house feature using the model. The higher the R², the better your model explains the relationship between the variables.\n",
    "\n",
    "In essence, R² helps you understand how much of the variability in one variable (like price) is captured or explained by another variable (like size of house) through your formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: LinearRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.5137848824526513\n",
      "R^2 score: 0.6144594222407171\n"
     ]
    }
   ],
   "source": [
    "# Import the Ridge model class from the linear_model module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup random seed\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "          \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "# The default score() metirc of regression aglorithms is R^2\n",
    "\n",
    "r = model.score(X_test, y_test)\n",
    "print(f\"R^2 score: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How many weight and bias parameters are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients (weights) for each feature:\n",
      "MedInc: 0.44318495086959414\n",
      "HouseAge: 0.009720455167713159\n",
      "AveRooms: -0.1149743739234838\n",
      "AveBedrms: 0.7612873947087113\n",
      "Population: -2.7550258373471796e-06\n",
      "AveOccup: -0.004123962992775818\n",
      "Latitude: -0.4251944662850576\n",
      "Longitude: -0.43750899277720684\n",
      "\n",
      "Intercept (bias): -37.2820104162937\n"
     ]
    }
   ],
   "source": [
    "weights = model.coef_\n",
    "\n",
    "# Get intercept (bias)\n",
    "bias = model.intercept_\n",
    "\n",
    "print(\"Coefficients (weights) for each feature:\")\n",
    "for feature, weight in zip(X.columns, weights):\n",
    "    print(f\"{feature}: {weight}\")\n",
    "\n",
    "print(\"\\nIntercept (bias):\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation r2 Scores: [0.54866323 0.46820691 0.55078434 0.53698703 0.66051406]\n",
      "Cross-Validation r2 Score: 0.5530311140279556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation r2 Scores:\", cv_scores)\n",
    "print(\"Cross-Validation r2 Score:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, weights and biases are fundamental components of many models, especially in neural networks and certain linear models.\n",
    "\n",
    "- **Weights:** In machine learning, weights refer to the coefficients attributed to the input features in a model. For instance, in a linear regression model, each feature has a corresponding weight that determines its contribution to the output prediction. In neural networks, weights represent the strengths of connections between neurons in different layers.\n",
    "\n",
    "- **Biases:** Biases are additional parameters in a model that allow shifting the output, providing more flexibility and expressiveness. In a neural network, biases are added to the weighted sum of inputs and act similarly to intercepts in linear models. They allow the model to represent patterns even when all input features are zeros.\n",
    "\n",
    "Here's a simple example in a linear regression equation:\n",
    "\n",
    "y = w_1 * feature_1 + w_2 * feature_2 + ... + w_n * feature_n + b \n",
    "\n",
    "- \\(w_1, w_2, ... , w_n\\) are the weights associated with each feature.\n",
    "-  b is the bias term.\n",
    "\n",
    "During the training process, these weights and biases are adjusted iteratively to minimize the error between predicted outputs and actual targets. This process involves optimization algorithms like gradient descent, where the model learns the best values for weights and biases to make accurate predictions on unseen data.\n",
    "\n",
    "In neural networks, these parameters become more complex, as there are multiple layers with interconnected neurons, each having its set of weights and biases. Adjusting these parameters through techniques like backpropagation with gradient descent is crucial for training neural networks effectively.\n",
    "\n",
    "Understanding and optimizing these parameters are essential for improving a model's performance and generalization to new, unseen data. They play a significant role in the representational power and flexibility of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step : \n",
    "\n",
    "\n",
    "What if `LinearRegression` didn't work? Or what if we wanted to improve our results?\n",
    "\n",
    "The next step would be to try other models. It is an ensemble model in which multiple models put together to make a decision.\n",
    "\n",
    "One of the most common and useful ensemble methods is the [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest). Known for its fast training and prediction times and adaptibility to different problems. In ensemble model, multiple models put together to make a decision.\n",
    "\n",
    "The basic premise of the Random Forest is to combine a number of different decision trees, each one random from the other and make a prediction on a sample by averaging the result of each decision tree.\n",
    "\n",
    "An in-depth discussion of the Random Forest algorithm is beyond the scope of this notebook but if you're interested in learning more, [An Implementation and Explanation of the Random Forest in Python](https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76) by Will Koehrsen is a great read.\n",
    "\n",
    "Since we're working with regression, we'll use Scikit-Learn's [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "We can use the exact same workflow as Linear regresser. Except for changing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: RandomForestRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.2534073069137548\n",
      "R^2 score: 0.8066196804802649\n"
     ]
    }
   ],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = housing_df.drop(\"target\", axis=1)\n",
    "y = housing_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "# The default score() metirc of regression aglorithms is R^2\n",
    "\n",
    "r = model.score(X_test, y_test)\n",
    "print(f\"R^2 score: {r}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation r2 Scores: [0.80951797 0.79354052 0.81118186 0.80483983 0.80497546]\n",
      "Mean r2 Score: 0.8048111291645605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation r2 Scores:\", cv_scores)\n",
    "print(\"Mean r2 Score:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier\n",
    "model = RandomForestRegressor(n_estimators= 20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "# The default score() metirc of regression aglorithms is R^2\n",
    "\n",
    "r = model.score(X_test, y_test)\n",
    "print(f\"R^2 score: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter turning with grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 70}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to do it with GridSearchCV...\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameters to search over\n",
    "param_grid = {'n_estimators': [i for i in range(10, 100, 10)]}\n",
    "\n",
    "# Setup the grid search\n",
    "grid = GridSearchCV(RandomForestRegressor(),\n",
    "                    param_grid,\n",
    "                    cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Find the best parameters\n",
    "grid.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With GridSearchCV, different versions of the model with different hyperparameters are created. For each version, cross-validation is employed to assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Check the score of the model (on the test set)\n",
    "# The default score() metirc of regression aglorithms is R^2\n",
    "\n",
    "r = model.score(X_test, y_test)\n",
    "print(f\"R^2 score: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 3: Experiment with Additional Model - Ridge Regression\n",
    "In addition to the **LinearSVC** and **SVC with Linear Kernel** models, follow these steps to evaluate the performance of a **Ridge Regression** model:\n",
    "\n",
    "1. **Model 3: Ridge Regression**\n",
    "   - Import and initialize the Ridge Regression model:\n",
    "     ```python\n",
    "     from sklearn.linear_model import Ridge\n",
    "     model = Ridge()\n",
    "     ```\n",
    "   - Train the Ridge model using the same dataset.\n",
    "\n",
    "2. **Comparison**\n",
    "   - Evaluate the Ridge Regression model using **Mean Squared Error (MSE)** and **R² Score**.\n",
    "   - Compare these metrics against the evaluation results of the previous models."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e036ea145f52bb5f15dc913c23df31dcf3e5fc6207d09d4cecab06a90d0c7407"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
